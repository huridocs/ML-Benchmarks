There are not many models for each of the languages and in the ones we have tried they were not doing that well - especially in Arabic. These are some results for that:

CleanBeginningDot1000_ArabertBasev2 f1: 6.73% prec: 14.0% recall: 4.43% time: 445s
CleanBeginningDot1000_ArabicSBERT100K f1: 4.18% prec: 6.1% recall: 3.18% time: 446s

And when I trained on only Arabic data with the models we already have, these are the results:
CleanBeginningDot1000_AlibabaGTEMultilingualReranker f1: 6.6% prec: 12.96% recall: 4.43% time: 886s
CleanBeginningDot500_SetFitMultilingual f1: 6.32% prec: 20.0% recall: 3.75% time: 438s

Also for Spanish models:
CleanBeginningDot500_ParaphraseSpanishDistilroberta f1: 50.52% prec: 58.57% recall: 44.41% time: 275s
CleanBeginningDot500_SentenceSimilaritySpanish f1: 47.06% prec: 57.39% recall: 39.88% time: 267s

And when I trained on only Spanish data with the models we already have, these are the results:
CleanBeginningDot500_AlibabaGTEMultilingualReranker f1: 50.08% prec: 55.07% recall: 45.92% time: 525s
CleanBeginningDot500_SetFitMultilingual f1: 49.33% prec: 67.19% recall: 38.97% time: 462s
CleanBeginningDot1000_AlibabaGTEMultilingualReranker f1: 44.06% prec: 51.2% recall: 38.67% time: 600s
So, we are kind of not gaining anything.

Rather than using model per language, we are going to use one model for non-English documents and one other model for English documents. These are the results for these models:

25 other languages training samples - 100 other languages test samples:
CleanBeginningDot1000_SetFitMultiQAMpnetBaseDotv1 f1: 22.08% prec: 34.69% recall: 16.19% time: 100s
CleanBeginningDot1000_AlibabaGTEMultilingualReranker f1: 13.33% prec: 22.47% recall: 9.48% time: 166s
100 other languages training samples - 100 other languages test samples:
CleanBeginningDot1000_AlibabaGTEMultilingualReranker f1: 30.15% prec: 42.61% recall: 23.33% time: 620s
CleanBeginningDot1000_SetFitMultiQAMpnetBaseDotv1 f1: 25.49% prec: 41.05% recall: 18.48% time: 358s
25 other languages + 25 all_cyrilla_keywords english training samples - 100 other languages test samples:
CleanBeginningDot1000_AlibabaGTEMultilingualReranker f1: 25.55% prec: 55.56% recall: 16.59% time: 419s
CleanBeginningDot1000_SetFitMultiQAMpnetBaseDotv1 f1: 24.26% prec: 54.1% recall: 15.64% time: 231s
100 other languages + 100 all_cyrilla_keywords english training samples - 100 other languages test samples:
CleanBeginningDot1000_AlibabaGTEMultilingualReranker f1: 39.09% prec: 48.59% recall: 32.7% time: 617s
CleanBeginningDot1000_SetFitMultiQAMpnetBaseDotv1 f1: 28.37% prec: 51.9% recall: 19.52% time: 333s
all_cyrilla_keywords 25 english training samples - 100 english test samples:
CleanBeginningDot1000_SetFitMultiQAMpnetBaseDotv1 f1: 16.78% prec: 54.55% recall: 9.92% time: 84s
CleanBeginningDot1000_AlibabaGTEMultilingualReranker f1: 8.36% prec: 26.67% recall: 4.96% time: 174s
all_cyrilla_keywords 100 english training samples - 100 english test samples:
CleanBeginningDot1000_AlibabaGTEMultilingualReranker f1: 35.47% prec: 68.24% recall: 23.97% time: 587s
CleanBeginningDot1000_SetFitMultiQAMpnetBaseDotv1 f1: 29.54% prec: 57.83% recall: 19.83% time: 304s
all_cyrilla_keywords 25 english + 25 other languages training samples - 100 english test samples:
CleanBeginningDot1000_SetFitMultiQAMpnetBaseDotv1 f1: 25.91% prec: 66.1% recall: 16.12% time: 225s
CleanBeginningDot1000_AlibabaGTEMultilingualReranker f1: 14.04% prec: 46.51% recall: 8.26% time: 433s
all_cyrilla_keywords 100 english + 100 other languages training samples - 100 english test samples:
CleanBeginningDot1000_SetFitMultiQAMpnetBaseDotv1 f1: 35.29% prec: 70.37% recall: 23.55% time: 330s
CleanBeginningDot1000_AlibabaGTEMultilingualReranker f1: 29.27% prec: 55.81% recall: 19.83% time: 605s