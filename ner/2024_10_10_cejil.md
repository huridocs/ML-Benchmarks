These are the results from some models I have tested on labels "organization", "location/gpe", "person":

<h3>English Documents Results</h3>


cejil3 \[4 page document\] - page 1:

| Model                                       | Correct | False Positive | Not Found | Precision | Recall | F1   | Time   | 
|---------------------------------------------|---------|----------------|-----------|-----------|--------|------|--------|
| en_core_web_sm (spacy)                      | 21      | 6              | 4         | 0.78      | 0.84   | 0.81 | 1.39s  |
| dslim/bert-base-NER                         | 14      | 18             | 4         | 0.44      | 0.78   | 0.56 | 4.47s  |
| urchade/gliner-multi-v2.1                   | 25      | 5              | 2         | 0.83      | 0.93   | 0.86 | 5.02s  |
| xlm-roberta-large-finetuned-conll03-english | 25      | 3              | 1         | 0.89      | 0.96   | 0.92 | 9.85s  |
| flair_ner_english                           | 22      | 3              | 5         | 0.88      | 0.82   | 0.85 | 7.64s  |
| flair_ner_multilingual_large                | 28      | 1              | 1         | 0.97      | 0.97   | 0.97 | 1.24s  |
| flair_ner_ontonotes_multilingual_large      | 29      | 2              | -         | 0.94      | 1      | 0.97 | 1.28s  |


cejil_staging14 \[20 page document\] - page 1:

| Model                                       | Correct | False Positive | Not Found | Precision | Recall | F1   | Time   | 
|---------------------------------------------|---------|----------------|-----------|-----------|--------|------|--------|
| en_core_web_sm (spacy)                      | 25      | 14             | 3         | 0.64      | 0.89   | 0.75 | 5.87s  |
| dslim/bert-base-NER                         | 27      | 11             | 3         | 0.71      | 0.9    | 0.79 | 17.07s |
| urchade/gliner-multi-v2.1                   | 31      | 11             | 3         | 0.74      | 0.91   | 0.82 | 39.36s |
| xlm-roberta-large-finetuned-conll03-english | 29      | 4              | 1         | 0.88      | 0.97   | 0.92 | 50.81s |
| flair_ner_english                           | 29      | 1              | 3         | 0.97      | 0.91   | 0.94 | 67.09s |
| flair_ner_multilingual_large                | 32      | -              | 1         | 1         | 0.97   | 0.98 | 10.32s |
| flair_ner_ontonotes_multilingual_large      | 31      | 1              | 1         | 0.97      | 0.97   | 0.97 | 10.79s |


---

<h3>Spanish Documents Results</h3>


cejil1 \[12 page document\] - page 1:

| Model                                       | Correct | False Positive | Not Found | Precision | Recall | F1   | Time   | 
|---------------------------------------------|---------|----------------|-----------|-----------|--------|------|--------|
| es_core_news_sm (spacy)                     | 20      | 6              | 7         | 0.77      | 0.74   | 0.75 | 2.6s   |
| dslim/bert-base-NER                         | 17      | 19             | 4         | 0.47      | 0.81   | 0.59 | 11.58s |
| urchade/gliner-multi-v2.1                   | 34      | 6              | 4         | 0.85      | 0.89   | 0,87 | 19.45s |
| xlm-roberta-large-finetuned-conll03-english | 28      | 5              | 5         | 0.85      | 0.85   | 0,85 | 23.73s |
| flair_ner_spanish_large                     | 32      | 4              | 1         | 0.89      | 0.97   | 0,93 | 4.67s  |
| flair_ner_multilingual_large                | 32      | 1              | 2         | 0.97      | 0.94   | 0,95 | 4.66s  |
| flair_ner_ontonotes_multilingual_large      | 30      | 4              | 1         | 0.88      | 0.97   | 0,92 | 4.83s  |


cejil_staging41 \[15 page document\] - page 1:

| Model                                       | Correct | False Positive | Not Found | Precision | Recall | F1   | Time   | 
|---------------------------------------------|---------|----------------|-----------|-----------|--------|------|--------|
| es_core_news_sm (spacy)                     | 18      | 16             | 8         | 0.53      | 0.69   | 0.6  | 4.7s   |
| dslim/bert-base-NER                         | 12      | 39             | 3         | 0.24      | 0.8    | 0.37 | 19.62s |
| urchade/gliner-multi-v2.1                   | 26      | 13             | 4         | 0.67      | 0.87   | 0,76 | 33.95s |
| xlm-roberta-large-finetuned-conll03-english | 25      | 2              | 4         | 0.93      | 0.86   | 0,89 | 44.16s |
| flair_ner_spanish_large                     | 33      | -              | -         | 1         | 1      | 1    | 9.03s  |
| flair_ner_multilingual_large                | 30      | 2              | 1         | 0.94      | 0.97   | 0.95 | 8.2s   |
| flair_ner_ontonotes_multilingual_large      | 28      | 2              | 2         | 0.93      | 0.93   | 0,93 | 9.67s  |


Notes:
--
- GLiNER is a zero-shot model. We can pass any label we want to search. It's overall performing well but Flair models seems to be better on these labels.
- There are different kinds of Flair models that capture different kinds of labels and languages. For more information: https://flairnlp.github.io/docs/tutorial-basics/tagging-entities

I will continue looking for other models, let's see.